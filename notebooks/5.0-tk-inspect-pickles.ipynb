{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickles(pickles_dir):\n",
    "    for filename in os.listdir(pickles_dir):\n",
    "        with open(os.path.join(pickles_dir, filename), 'rb') as f:\n",
    "            save_dict = pickle.load(f)\n",
    "        yield save_dict, filename\n",
    "\n",
    "def write_pickle(save_dict, pickle_path):\n",
    "    with open(pickle_path, 'wb') as f:\n",
    "        pickle.dump(save_dict, f)\n",
    "\n",
    "def compare(arr1, arr2):\n",
    "    left = list(np.copy(arr1))\n",
    "    for elem in arr2:\n",
    "        if elem not in left:\n",
    "            print(f'B contains {elem} while A does not')\n",
    "        else:\n",
    "            left.remove(elem)\n",
    "    for elem in left:\n",
    "        print(f'A contains {elem} while B does not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:  Syn Extreme Outliers (pol=0.0, anom=0.01)\n",
      "Syn Extreme Outliers (pol=0.0, anom=0.023)\n",
      "Syn Extreme Outliers (pol=0.0, anom=0.05)\n",
      "Syn Extreme Outliers (pol=0.0, anom=0.2)\n",
      "Syn Extreme Outliers (pol=0.0, anom=0.5)\n",
      "Syn Extreme Outliers (pol=0.25, anom=0.01)\n",
      "Syn Extreme Outliers (pol=0.25, anom=0.023)\n",
      "Syn Extreme Outliers (pol=0.25, anom=0.05)\n",
      "Syn Extreme Outliers (pol=0.25, anom=0.2)\n",
      "Syn Extreme Outliers (pol=0.25, anom=0.5)\n",
      "Syn Extreme Outliers (pol=0.5, anom=0.01)\n",
      "Syn Extreme Outliers (pol=0.5, anom=0.023)\n",
      "Syn Extreme Outliers (pol=0.5, anom=0.05)\n",
      "Syn Extreme Outliers (pol=0.5, anom=0.2)\n",
      "Syn Extreme Outliers (pol=0.5, anom=0.5)\n",
      "Syn Extreme Outliers (pol=0.75, anom=0.01)\n",
      "Syn Extreme Outliers (pol=0.75, anom=0.023)\n",
      "Syn Extreme Outliers (pol=0.75, anom=0.05)\n",
      "Syn Extreme Outliers (pol=0.75, anom=0.2)\n",
      "Syn Extreme Outliers (pol=0.75, anom=0.5)\n",
      "Syn Extreme Outliers (pol=1.0, anom=0.01)\n",
      "Syn Extreme Outliers (pol=1.0, anom=0.023)\n",
      "Syn Extreme Outliers (pol=1.0, anom=0.05)\n",
      "Syn Extreme Outliers (pol=1.0, anom=0.2)\n",
      "Syn Extreme Outliers (pol=1.0, anom=0.5)\n",
      "Add detectors:  ['LSTMED', 'DAGMM-NN', 'DAGMM-NW', 'DAGMM-LW', 'Recurrent EBM', 'Donut']\n",
      "Add detectors:  ['AutoEncoder', 'LSTMED']\n"
     ]
    }
   ],
   "source": [
    "datasets = None\n",
    "detectors = []\n",
    "\n",
    "path = os.path.join('..', 'reports', 'experiment_pollution', 'extreme_1', 'evaluators')\n",
    "save_dicts_1 = []\n",
    "for save_dict, filename in load_pickles(path):\n",
    "    assert datasets is None or np.array_equal(datasets, save_dict['datasets'])\n",
    "    if datasets is None:\n",
    "        datasets = save_dict['datasets']\n",
    "        print('Datasets: ', '\\n'.join(datasets))\n",
    "    if not np.array_equal(detectors, save_dict['detectors']):\n",
    "        print('Add detectors: ', save_dict['detectors'])\n",
    "        detectors += save_dict['detectors']\n",
    "    save_dict['_filename'] = os.path.join(filename)\n",
    "    save_dicts_1.append(save_dict)\n",
    "\n",
    "path = os.path.join('..', 'reports', 'experiment_pollution', 'extreme_1', 'additional_evaluators')\n",
    "save_dicts_2 = []\n",
    "for save_dict, _ in load_pickles(path):\n",
    "    assert datasets is None or np.array_equal(datasets, save_dict['datasets']), compare(datasets, save_dict['datasets'])\n",
    "    datasets = datasets or save_dict['datasets']\n",
    "    if not all([det in detectors for det in save_dict['detectors']]):\n",
    "        print('Add detectors: ', save_dict['detectors'])\n",
    "        detectors += save_dict['detectors']\n",
    "    save_dicts_2.append(save_dict)\n",
    "\n",
    "\n",
    "# --- Merge results --- #\n",
    "\n",
    "path = os.path.join('..', 'reports', 'experiment_pollution', 'extreme_1', 'evaluators_merged')\n",
    "os.makedirs(path, exist_ok=True)\n",
    "for dict1, dict2 in zip(save_dicts_1, save_dicts_2):\n",
    "    # We don't need the results values so drop them\n",
    "    dict1['results'] = None\n",
    "    dict1['seed'] = None\n",
    "    \n",
    "    # Drop results of old algorithm\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'][dict1['benchmark_results'].algorithm != 'LSTMED']\n",
    "    \n",
    "    dict1['detectors'].append('AutoEncoder')\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'].append(dict2['benchmark_results'])\n",
    "    \n",
    "    file_path = os.path.join(path, dict1['_filename'])\n",
    "    dict1['_filename'] = None\n",
    "    write_pickle(dict1, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter LSTMED from first collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36 (MP)",
   "language": "python",
   "name": "venv_mp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
