{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickles(pickles_dir):\n",
    "    for filename in os.listdir(pickles_dir):\n",
    "        with open(os.path.join(pickles_dir, filename), 'rb') as f:\n",
    "            save_dict = pickle.load(f)\n",
    "        yield save_dict, filename\n",
    "\n",
    "def write_pickle(save_dict, pickle_path):\n",
    "    with open(pickle_path, 'wb') as f:\n",
    "        pickle.dump(save_dict, f)\n",
    "\n",
    "def compare(arr1, arr2):\n",
    "    left = list(np.copy(arr1))\n",
    "    for elem in arr2:\n",
    "        if elem not in left:\n",
    "            print(f'B contains {elem} while A does not')\n",
    "        else:\n",
    "            left.remove(elem)\n",
    "    for elem in left:\n",
    "        print(f'A contains {elem} while B does not')\n",
    "\n",
    "def load_and_check(path):\n",
    "    global datasets, detectors\n",
    "    save_dicts = []\n",
    "    for save_dict, filename in load_pickles(path):\n",
    "        assert datasets is None or np.array_equal(datasets, save_dict['datasets']), compare(datasets, save_dict['datasets'])\n",
    "        if datasets is None:\n",
    "            datasets = save_dict['datasets']\n",
    "            print('Datasets: ', '\\n'.join(datasets))\n",
    "        if not all([det in detectors for det in save_dict['detectors']]):\n",
    "            print('Add detectors: ', save_dict['detectors'])\n",
    "            detectors += save_dict['detectors']\n",
    "        save_dict['_filename'] = os.path.join(filename)\n",
    "        save_dicts.append(save_dict)\n",
    "    return save_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:  Syn Trend Outliers (pol=0.0, anom=0.05))\n",
      "Syn Trend Outliers (pol=0.0, anom=0.1))\n",
      "Syn Trend Outliers (pol=0.0, anom=0.4))\n",
      "Syn Trend Outliers (pol=0.0125, anom=0.05))\n",
      "Syn Trend Outliers (pol=0.025, anom=0.1))\n",
      "Syn Trend Outliers (pol=0.1, anom=0.4))\n",
      "Syn Trend Outliers (pol=0.025, anom=0.05))\n",
      "Syn Trend Outliers (pol=0.05, anom=0.1))\n",
      "Syn Trend Outliers (pol=0.2, anom=0.4))\n",
      "Syn Trend Outliers (pol=0.037500000000000006, anom=0.05))\n",
      "Syn Trend Outliers (pol=0.07500000000000001, anom=0.1))\n",
      "Syn Trend Outliers (pol=0.30000000000000004, anom=0.4))\n",
      "Syn Trend Outliers (pol=0.05, anom=0.05))\n",
      "Syn Trend Outliers (pol=0.1, anom=0.1))\n",
      "Syn Trend Outliers (pol=0.4, anom=0.4))\n",
      "Add detectors:  ['AutoEncoder', 'DAGMM-NW', 'DAGMM-LW', 'Recurrent EBM', 'Donut']\n",
      "B contains Syn Trend Outliers (pol=0.0, anom=0.05) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.0, anom=0.1) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.0, anom=0.2) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.0, anom=0.4) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.0, anom=0.8) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.25, anom=0.05) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.25, anom=0.1) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.25, anom=0.2) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.25, anom=0.4) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.25, anom=0.8) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.5, anom=0.05) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.5, anom=0.1) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.5, anom=0.2) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.5, anom=0.4) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.5, anom=0.8) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.75, anom=0.05) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.75, anom=0.1) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.75, anom=0.2) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.75, anom=0.4) while A does not\n",
      "B contains Syn Trend Outliers (pol=0.75, anom=0.8) while A does not\n",
      "B contains Syn Trend Outliers (pol=1.0, anom=0.05) while A does not\n",
      "B contains Syn Trend Outliers (pol=1.0, anom=0.1) while A does not\n",
      "B contains Syn Trend Outliers (pol=1.0, anom=0.2) while A does not\n",
      "B contains Syn Trend Outliers (pol=1.0, anom=0.4) while A does not\n",
      "B contains Syn Trend Outliers (pol=1.0, anom=0.8) while A does not\n",
      "A contains Syn Trend Outliers (pol=0.0, anom=0.05)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.0, anom=0.1)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.0, anom=0.4)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.0125, anom=0.05)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.025, anom=0.1)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.1, anom=0.4)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.025, anom=0.05)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.05, anom=0.1)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.2, anom=0.4)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.037500000000000006, anom=0.05)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.07500000000000001, anom=0.1)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.30000000000000004, anom=0.4)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.05, anom=0.05)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.1, anom=0.1)) while B does not\n",
      "A contains Syn Trend Outliers (pol=0.4, anom=0.4)) while B does not\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-569749f2cda2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpath_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reports/experiment_pollution/trend_1/all_only_0.2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msave_dicts_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_and_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# --- Merge results --- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-46faf7a8b8a9>\u001b[0m in \u001b[0;36mload_and_check\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0msave_dicts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mload_pickles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datasets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datasets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'datasets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "datasets = None\n",
    "detectors = []\n",
    "\n",
    "path_1 = os.path.join('..', 'reports/experiment_pollution/trend_1/all_except_0.2_old_ds')\n",
    "save_dicts_1 = load_and_check(path_1)\n",
    "\n",
    "path_2 = os.path.join('..', 'reports/experiment_pollution/trend_1/all_only_0.2')\n",
    "save_dicts_2 = load_and_check(path_2)\n",
    "\n",
    "# --- Merge results --- #\n",
    "\n",
    "path = os.path.join('..', 'reports', 'experiment_pollution', 'trend_1', 'evaluators')\n",
    "os.makedirs(path, exist_ok=True)\n",
    "for dict1, dict2, dict3 in zip(save_dicts_1, save_dicts_2, save_dicts_3):\n",
    "    # We don't need the results values so drop them\n",
    "    dict1['results'] = None\n",
    "    dict1['seed'] = None\n",
    "    \n",
    "    # Drop results of old algorithm\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'][dict1['benchmark_results'].algorithm != 'LSTMED']\n",
    "    \n",
    "    dict1['detectors'].append('AutoEncoder')\n",
    "    dict1['detectors'].append('LSTM-AD')\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'].append(dict2['benchmark_results'], ignore_index=True)\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'].append(dict3['benchmark_results'], ignore_index=True)\n",
    "    \n",
    "    file_path = os.path.join(path, dict1['_filename'])\n",
    "    dict1['_filename'] = None\n",
    "    # write_pickle(dict1, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter LSTMED from first collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge three folders, replace LSTMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = None\n",
    "detectors = []\n",
    "\n",
    "path_1 = os.path.join('..', 'reports', 'experiment_pollution', 'trend_1', 'evaluators_old')\n",
    "save_dicts_1 = load_and_check(path_1)\n",
    "\n",
    "path_2 = os.path.join('..', 'reports', 'experiment_pollution', 'trend_1', 'additional_evaluators_lstmad')\n",
    "save_dicts_2 = load_and_check(path_2)\n",
    "\n",
    "path_3 = os.path.join('..', 'reports', 'experiment_pollution', 'trend_1', 'additional_evaluators_lstmad')\n",
    "save_dicts_3 = load_and_check(path_3)\n",
    "\n",
    "\n",
    "# --- Merge results --- #\n",
    "\n",
    "path = os.path.join('..', 'reports', 'experiment_pollution', 'trend_1', 'evaluators')\n",
    "os.makedirs(path, exist_ok=True)\n",
    "for dict1, dict2, dict3 in zip(save_dicts_1, save_dicts_2, save_dicts_3):\n",
    "    # We don't need the results values so drop them\n",
    "    dict1['results'] = None\n",
    "    dict1['seed'] = None\n",
    "    \n",
    "    # Drop results of old algorithm\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'][dict1['benchmark_results'].algorithm != 'LSTMED']\n",
    "    \n",
    "    dict1['detectors'].append('AutoEncoder')\n",
    "    dict1['detectors'].append('LSTM-AD')\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'].append(dict2['benchmark_results'], ignore_index=True)\n",
    "    dict1['benchmark_results'] = dict1['benchmark_results'].append(dict3['benchmark_results'], ignore_index=True)\n",
    "    \n",
    "    file_path = os.path.join(path, dict1['_filename'])\n",
    "    dict1['_filename'] = None\n",
    "    write_pickle(dict1, file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36 (MP)",
   "language": "python",
   "name": "venv_mp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
